{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941ad3f7",
   "metadata": {},
   "source": [
    "# Septin Analysis: comparing the mean shape of each group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9d4ef",
   "metadata": {},
   "source": [
    "# 1. Overview of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc995bfc",
   "metadata": {},
   "source": [
    "First, we will"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d77307",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d4074",
   "metadata": {},
   "source": [
    "## 2.1 Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc54e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using pytorch backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:  /Users/adelemyers/code/dyn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "import geomstats.backend as gs\n",
    "\n",
    "geomstats_gitroot_path = subprocess.check_output(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], universal_newlines=True\n",
    ")\n",
    "os.chdir(geomstats_gitroot_path[:-1])\n",
    "print(\"Working directory: \", os.getcwd())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f035173",
   "metadata": {},
   "source": [
    "## 2.2 Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3956044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287b7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomstats.learning.pca import TangentPCA\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from sklearn import manifold\n",
    "from joblib import Parallel, delayed\n",
    "from numba import jit, njit, prange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93332949",
   "metadata": {},
   "source": [
    "## 2.3 Project-specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c68d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomstats.geometry.discrete_curves import R2, DiscreteCurves, ClosedDiscreteCurves\n",
    "\n",
    "from geomstats.learning.frechet_mean import FrechetMean\n",
    "from geomstats.learning.kmeans import RiemannianKMeans\n",
    "\n",
    "import dyn.dyn.datasets.experimental as experimental\n",
    "import dyn.dyn.features.basic as basic\n",
    "import dyn.viz as viz\n",
    "\n",
    "viz.init_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ffb9e",
   "metadata": {},
   "source": [
    "# 3. Load the datasets of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ec0ac",
   "metadata": {},
   "source": [
    "## 3.1 testing the method i will add to experiemental.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc660dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.datasets.utils as data_utils\n",
    "import numpy as np\n",
    "import skimage.io as skio\n",
    "from geomstats.geometry.pre_shape import PreShapeSpace\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import dyn.dyn.features.basic as basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82bbbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dyn.dyn.datasets.experimental as experimental\n",
    "\n",
    "import importlib\n",
    "importlib.reload(experimental)\n",
    "\n",
    "\n",
    "\n",
    "def _tif_video_to_lists(tif_path):\n",
    "    \"\"\"Convert a cell video into two trajectories of contours and images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tif_path : absolute path of video in .tif format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    contours_list : list of arrays\n",
    "        List of 2D coordinates of points defining the contours of each cell\n",
    "        within the video.\n",
    "    imgs_list : list of array\n",
    "        List of images in the input video.\n",
    "    \"\"\"\n",
    "    img_stack = skio.imread(tif_path, plugin=\"tifffile\")\n",
    "    contours_list = []\n",
    "    imgs_list = []\n",
    "    for img in img_stack:\n",
    "        imgs_list.append(img)\n",
    "        thresh = threshold_otsu(img)\n",
    "        binary = img > thresh\n",
    "        contours = measure.find_contours(binary, 0.8)\n",
    "        lengths = [len(c) for c in contours]\n",
    "        max_length = max(lengths)\n",
    "        index_max_length = lengths.index(max_length)\n",
    "        contours_list.append(contours[index_max_length])\n",
    "\n",
    "    return contours_list, imgs_list\n",
    "\n",
    "def _interpolate(curve, n_sampling_points):\n",
    "    \"\"\"Interpolate a discrete curve with nb_points from a discrete curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    curve : array-like, shape=[n_points, 2]\n",
    "    n_sampling_points : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interpolation : array-like, shape=[n_sampling_points, 2]\n",
    "       Discrete curve with n_sampling_points\n",
    "    \"\"\"\n",
    "    old_length = curve.shape[0]\n",
    "    interpolation = np.zeros((n_sampling_points, 2))\n",
    "    incr = old_length / n_sampling_points\n",
    "    pos = np.array(0.0, dtype=np.float32)\n",
    "    for i in range(n_sampling_points):\n",
    "        index = int(np.floor(pos))\n",
    "        interpolation[i] = curve[index] + (pos - index) * (\n",
    "            curve[(index + 1) % old_length] - curve[index]\n",
    "        )\n",
    "        pos += incr\n",
    "    return gs.array(interpolation, dtype=gs.float32)\n",
    "\n",
    "def _remove_consecutive_duplicates(curve, tol=1e-2):\n",
    "    \"\"\"Preprocess curve to ensure that there are no consecutive duplicate points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    curve : discrete curve\n",
    "    \"\"\"\n",
    "    dist = curve[1:] - curve[:-1]\n",
    "    dist_norm = gs.sqrt(gs.sum(dist**2, axis=1))\n",
    "\n",
    "    if gs.any(dist_norm < tol):\n",
    "        for i in range(len(curve) - 1):\n",
    "            if gs.sqrt(gs.sum((curve[i + 1] - curve[i]) ** 2, axis=0)) < tol:\n",
    "                curve[i + 1] = (curve[i] + curve[i + 2]) / 2\n",
    "\n",
    "    return curve\n",
    "\n",
    "\n",
    "\n",
    "def load_septin_cells(n_cells=-1, n_sampling_points=10):\n",
    "    n_sampling_points=10\n",
    "    n_cells=-1\n",
    "\n",
    "    control_tifs, septin_knockdown_tifs, septin_overexpression_tifs = experimental.load_septin_cells(\n",
    "        n_cells,n_sampling_points)\n",
    "    \n",
    "    list_tifs=control_tifs\n",
    "    \n",
    "    n_groups = 3\n",
    "    \n",
    "    \"\"\"\n",
    "    #n_traj = len(list_tifs)\n",
    "    #print(n_traj)\n",
    "    #before, this was called one_img_stack because it was used to come up with n_time_points and other variables\n",
    "    #because before, there were multiple image stacks. here, list_tifs is one image stack, so we will change\n",
    "    #one_img_stack -> img_stack\n",
    "    \"\"\"\n",
    "    \n",
    "    #finding dimensions of the control data\n",
    "    control_img_stack = skio.imread(control_tifs, plugin=\"tifffile\")\n",
    "    print(control_img_stack.shape)\n",
    "    c_n_time_points, c_height, c_width = control_img_stack.shape\n",
    "    \n",
    "    #finding the dimensions of the septin knockdown data\n",
    "    knock_img_stack = skio.imread(septin_knockdown_tifs, plugin=\"tifffile\")\n",
    "    print(knock_img_stack.shape)\n",
    "    k_n_time_points,k_height, k_width = knock_img_stack.shape\n",
    "    \n",
    "    #finding the dimensions of the septin overexpression data\n",
    "    overexp_img_stack = skio.imread(septin_overexpression_tifs, plugin=\"tifffile\")\n",
    "    print(overexp_img_stack.shape)\n",
    "    o_n_time_points,o_height, o_width = overexp_img_stack.shape\n",
    "    \n",
    "    #centers_traj = gs.zeros((n_groups, n_time_points, 2))\n",
    "    #shapes_traj = gs.zeros((n_groups, n_time_points, n_sampling_points, 2))\n",
    "    #imgs_traj = gs.zeros((n_groups, n_time_points, height, width))\n",
    "\n",
    "    centers_control = gs.zeros((c_n_time_points, 2))\n",
    "    shapes_control = gs.zeros((c_n_time_points, n_sampling_points, 2))\n",
    "    imgs_control = gs.zeros((c_n_time_points, c_height, c_width))\n",
    "    \n",
    "    centers_knock = gs.zeros((k_n_time_points, 2))\n",
    "    shapes_knock = gs.zeros((k_n_time_points, n_sampling_points, 2))\n",
    "    imgs_knock = gs.zeros((k_n_time_points, k_height, k_width))\n",
    "    \n",
    "    centers_overexp = gs.zeros((o_n_time_points, 2))\n",
    "    shapes_overexp = gs.zeros((o_n_time_points, n_sampling_points, 2))\n",
    "    imgs_overexp = gs.zeros((o_n_time_points, o_height, o_width))\n",
    "\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    #for i_traj, video_path in enumerate(list_tifs):\n",
    "        #video_name = os.path.basename(video_path)\n",
    "        #print(f\"\\n Processing trajectory {i_traj+1}/{n_traj}.\")\n",
    "\n",
    "        #print(f\"Converting {video_name} into list of cell contours...\")\n",
    "\n",
    "    #this converts all the images into a list of contours and images.\n",
    "    contours_list, imgs_list = _tif_video_to_lists(list_tifs)\n",
    "\n",
    "    #labels.append(int(video_name.split(\"_\")[0]))\n",
    "    for i_contour, (contour, img) in enumerate(zip(contours_list, imgs_list)):\n",
    "        interpolated = _interpolate(contour, n_sampling_points)\n",
    "        cleaned = _remove_consecutive_duplicates(interpolated)\n",
    "        center = gs.mean(cleaned, axis=-2)\n",
    "        centered = cleaned - center[..., None, :]\n",
    "        centers_traj[i_contour] = center\n",
    "        shapes_traj[i_contour] = centered\n",
    "        if img.shape != (height, width):\n",
    "            print(\n",
    "                \"Found image of a different size: \"\n",
    "                f\"{img.shape} instead of {height, width}. \"\n",
    "                \"Skipped image (not cell contours).\"\n",
    "            )\n",
    "            continue\n",
    "        imgs_traj[i_contour] = gs.array(img.astype(float).T)\n",
    "    labels = gs.array(labels)\n",
    "    return centers_traj, shapes_traj, imgs_traj, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e50d608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 512, 512)\n",
      "(45, 512, 512)\n",
      "(36, 512, 512)\n",
      "<enumerate object at 0x7f77c71b41c0>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m centers_traj, shapes_traj, imgs_traj, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_septin_cells\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_sampling_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mload_septin_cells\u001b[0;34m(n_cells, n_sampling_points)\u001b[0m\n\u001b[1;32m    114\u001b[0m o_n_time_points,o_height, o_width \u001b[38;5;241m=\u001b[39m overexp_img_stack\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(control_tifs))\n\u001b[0;32m--> 118\u001b[0m video_name \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol_tifs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m centers_traj \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mzeros((n_groups, n_time_points, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    121\u001b[0m shapes_traj \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mzeros((n_groups, n_time_points, n_sampling_points, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/dyn/lib/python3.8/posixpath.py:142\u001b[0m, in \u001b[0;36mbasename\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbasename\u001b[39m(p):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns the final component of a pathname\"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     sep \u001b[38;5;241m=\u001b[39m _get_sep(p)\n\u001b[1;32m    144\u001b[0m     i \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mrfind(sep) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "centers_traj, shapes_traj, imgs_traj, labels = load_septin_cells(\n",
    "    n_sampling_points=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7b3e3",
   "metadata": {},
   "source": [
    "I think that the issue here is that all of this code is meant for something where the shape of list_tifs is bigger than the example case.\n",
    "\n",
    "yes, so what is happening is that it think that each file in the example is its own \"movie\"/set of trajectories, and in our case, we are considering just a bunch of single images. so the example list_tifs has an extra dimension. so we shouldnt even be considering the variable n_tifs\n",
    "\n",
    "yeah, so i was right. now, do the function below and just do it for each one because everything is set up differently from eample (list_tifs is different than actually just creating a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f41fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_septin_cells(n_cells=-1, n_sampling_points=10):\n",
    "    n_sampling_points=10\n",
    "    n_cells=-1\n",
    "\n",
    "    list_tifs = experimental.load_septin_cells(n_cells,n_sampling_points)\n",
    "\n",
    "    #n_traj = len(list_tifs)\n",
    "    #print(n_traj)\n",
    "    #before, this was called one_img_stack because it was used to come up with n_time_points and other variables\n",
    "    #because before, there were multiple image stacks. here, list_tifs is one image stack, so we will change\n",
    "    #one_img_stack -> img_stack\n",
    "    img_stack = skio.imread(list_tifs, plugin=\"tifffile\")\n",
    "    print(img_stack.shape)\n",
    "    n_time_points, height, width = img_stack.shape\n",
    "\n",
    "    #centers_traj = gs.zeros((n_traj, n_time_points, 2))\n",
    "    #shapes_traj = gs.zeros((n_traj, n_time_points, n_sampling_points, 2))\n",
    "    #imgs_traj = gs.zeros((n_traj, n_time_points, height, width))\n",
    "\n",
    "    centers_traj = gs.zeros((n_time_points, 2))\n",
    "    shapes_traj = gs.zeros((n_time_points, n_sampling_points, 2))\n",
    "    imgs_traj = gs.zeros((n_time_points, height, width))\n",
    "\n",
    "\n",
    "    labels = []\n",
    "    #for i_traj, video_path in enumerate(list_tifs):\n",
    "        #video_name = os.path.basename(video_path)\n",
    "        #print(f\"\\n Processing trajectory {i_traj+1}/{n_traj}.\")\n",
    "\n",
    "        #print(f\"Converting {video_name} into list of cell contours...\")\n",
    "\n",
    "    #this converts all the images into a list of contours and images.\n",
    "    contours_list, imgs_list = _tif_video_to_lists(list_tifs)\n",
    "\n",
    "    #labels.append(int(video_name.split(\"_\")[0]))\n",
    "    for i_contour, (contour, img) in enumerate(zip(contours_list, imgs_list)):\n",
    "        interpolated = _interpolate(contour, n_sampling_points)\n",
    "        cleaned = _remove_consecutive_duplicates(interpolated)\n",
    "        center = gs.mean(cleaned, axis=-2)\n",
    "        centered = cleaned - center[..., None, :]\n",
    "        centers_traj[i_contour] = center\n",
    "        shapes_traj[i_contour] = centered\n",
    "        if img.shape != (height, width):\n",
    "            print(\n",
    "                \"Found image of a different size: \"\n",
    "                f\"{img.shape} instead of {height, width}. \"\n",
    "                \"Skipped image (not cell contours).\"\n",
    "            )\n",
    "            continue\n",
    "        imgs_traj[i_contour] = gs.array(img.astype(float).T)\n",
    "    labels = gs.array(labels)\n",
    "    return centers_traj, shapes_traj, imgs_traj, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0a727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('dyn': conda)",
   "language": "python",
   "name": "python381364bitdyncondaf9551b40dbe44ba5b6a4ba972ca87957"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
